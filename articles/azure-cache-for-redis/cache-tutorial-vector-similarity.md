---
title: 'Tutorial: Conduct vector similarity search on Azure OpenAI embeddings using Azure Cache for Redis'
description: In this tutorial, you learn how to use Azure Cache for Redis to store and search for vector embeddings.
author: flang-msft
ms.author: franlanglois
ms.service: cache
ms.topic: tutorial
ms.date: 09/15/2023

#CustomerIntent: As a < type of user >, I want < what? > so that < why? >.
---

# Tutorial: Conduct vector similarity search on Azure OpenAI embeddings using Azure Cache for Redis

In this tutorial, you will walk through a basic vector similarity search use-case. You'll use embeddings generated by Azure OpenAI Service and the built-in vector search capabilities of the Enterprise tier of Azure Cache for Redis to query a dataset of movies to find the most relevant match.

The tutorial uses the [Wikipedia Movie Plots dataset](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) that features plot descriptions of over 35,000 movies from wikipedia covering the years 1901 to 2017.
The dataset includes a plot summary for each movie, plus metadata such as the year the film was released, the director(s), main cast, and genre. You will follow the steps of the tutorial to generate embeddings based on the plot summary and use the other metadata to run hybrid queries.

In this tutorial, you learn how to:

> [!div class="checklist"]
> * Create an Azure Cache for Redis instance configured for vector search
> * Install Azure OpenAI and other required Python libraries.
> * Download the movie dataset and prepare it for analysis.
> * Use the **text-embedding-ada-002 (Version 2)** model to generate embeddings.
> * Create a vector index in Azure Cache for Redis
> * Use cosine similarity to rank search results.
> * Use hybrid query functionality through [RediSearch]() to prefilter the data and make the vector search even more powerful.

## Prerequisites

* An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)
* Access granted to Azure OpenAI in the desired Azure subscription
    Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at <a href="https://aka.ms/oai/access" target="_blank">https://aka.ms/oai/access</a>.
* <a href="https://www.python.org/" target="_blank">Python 3.7.1 or later version</a>
* [Jupyter Notebooks](https://jupyter.org/)
* An Azure OpenAI resource with the **text-embedding-ada-002 (Version 2)** model deployed. This model is currently only available in [certain regions](../concepts/models.md#model-summary-table-and-region-availability). See the [resource deployment guide](../how-to/create-resource.md) for instructions on how to deploy the model.

## Create an Azure Cache for Redis Instance

1. Follow the [Quickstart: Create a Redis Enterprise cache](quickstart-create-redis-enterprise) guide. On the **Advanced** page, make sure that you've added the **RediSearch** module and have chosen the **Enterprise** Cluster Policy. All other settings can match the default described in the quickstart.

   It will take a few minutes for the cache to create. You can move on to the next step in the meantime.

<!--Fran, we could use a screenshot here so that people don't skip over this.-->

## Set up your development environment

1. Create a folder on your local computer named *redis-vector* in the location where you typically save your projects.
1. [Download the Jupyter notebook file named *tutorial.ipynb*](https://github.com/Azure-Samples/azure-cache-redis-samples/tree/main/tutorial/vector-similarity-search-open-ai) and save it into the new *redis-vector* folder.

1. Open the *tutorial.ipynb* file and execute the code cell containing the comment `Code cell 1`. This command installs the required Python packages.

<!--Alternatively, you can use our [requirements.txt file](https://github.com/Azure-Samples/Azure-OpenAI-Docs-Samples/blob/main/Samples/Tutorials/Embeddings/requirements.txt).-->
<!-- A tutorial is a single path through the instructions to achieve a specific outcome. Asking them to go to a whole other repo to find a single requirements.txt file might complicate things. Providing multiple options is better suited for a How-To Guide type article. -->

## Download the dataset

1. In a web browser, navigate to [https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots).

1. Sign in or register with Kaggle. Registration is required to download the file.

1. Select the **Download** link on Kaggle to download the *archive.zip* file.

1. Extract the *archive.zip* file and move the *wiki_movie_plots_deduped.csv* into the *redis-vector* folder.

## Connect to Azure Open AI service

To successfully make a call against Azure OpenAI, you'll need an **endpoint** and a **key**.

|Variable name | Value |
|--------------------------|-------------|
| `ENDPOINT`               | This value can be found in the **Keys & Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in **Azure OpenAI Studio** > **Playground** > **Code View**. An example endpoint is: `https://docs-test-001.openai.azure.com`.|
| `API-KEY` | This value can be found in the **Keys & Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|

1. Go to your Azure Open AI resource in the Azure portal.

1. Locate **Endpoint and Keys** in the **Resource Management** section. Copy your endpoint and access key as you'll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.

1. In the Jupyter notebook, locate the cell containing the comment `Code cell 2`. Update the following lines of code in the code cell below "Import libraries and set up Azure OpenaI service connection".

   ```python
   API_KEY = "<your-azure-openai-key>"
   RESOURCE_ENDPOINT = "<your-azure-openai-endpoint>"
   DEPLOYMENT_NAME = "<name-of-your-model-deployment>"
   ```

   Make sure to update the value of `API_KEY` and `RESOURCE_ENDPOINT` with the key and endpoint values from your Azure OpenAI deployment. `DEPLOYMENT_NAME` should be set to the name of your deployment using the `text-embedding-ada-002 (Version 2)` embeddings model.

   > [!Important]
   > We strongly recommend using environmental variables or a secret manager like [Azure Key Vault](../key-vault/general/overview) to pass in the API key, endpoint, and deployment name information. These variables are set in plaintext here for the sake of simplicity.

<!-- Run the following code in your preferred Python IDE. While we strongly recommend using Jupyter Notebooks, if you chose not to, you'll need to modify any code that is returning a pandas dataframe by using print(dataframe_name) rather than just calling the dataframe_name directly as is often done at the end of a code block. -->
<!-- Here again, we need to tell people exactly what to do. We're going to make an assumption that these are experienced Python / Pandas / Jupyter Notebook professionals. -->

1. Execute the code cell you just edited. You should see your model returned, confirming that the API call is configured correctly:

   ```output
   {
     "capabilities": {
       "fine_tune": false,
       "inference": true,
       "completion": false,
       "chat_completion": false,
       "embeddings": true
     },
     "lifecycle_status": "preview",
     "deprecation": {
       "inference": 1738454400
     },
     "id": "text-embedding-ada-002",
     "status": "succeeded",
     "created_at": 1675296000,
     "updated_at": 1675296000,
     "object": "model"
   }
   ```

   If no model is returned, check to make sure that you've [deployed a model](../ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) and your key, endpoint, and deployment name are correct.

## Import dataset into pandas and process data

Next, you will read the csv file into a pandas DataFrame.

1. Excecute the code cell with the comment `Code cell 3`. This code reads the csv into a pandas DataFrame.

   ```python
   df=pd.read_csv(os.path.join(os.getcwd(),'wiki_movie_plots_deduped.csv'))
   df
   ```

   The output should look something like this:

<!--Fran, we could use a screenshot here-->

1. Excecute the code cell with the comment `Code cell 4`. This cell processes the data by adding an id index, removing spaces from the column titles, and filters the movies to take only movies made after 1970 and from english speaking countries. This filtering step reduces the number of movies in the dataset, which lowers the cost and time required to generate embeddings. You are free to change or remove the filter parameters based on your preferences.

1. Execute the code cell with the comment `Code cell 5`. This code cell creates a function to clean the data by removing whitespace and punctuation, then uses it against the dataframe containing the plot.

1. Execute the code cell with the commen `Code cell 6`. This cell removes any entries that contain plot descriptions that are too long for the embeddings model. (In other words, they require more tokens than the 8192 token limit.)

   You should see this output:

   ```output
   Number of movies: 11125
   Number of tokens required:7044844
   ```

   > [!Important]
   > Refer to [Azure OpenAI Service pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/) to caculate the cost of generating embeddings based on the number of tokens required.

## Generate embeddings

Now that the data has been loaded and filtered, we will create embeddings so we can query on the plot for each movie.

1. Execute the code cell with the comment `Code cell 7`. This can take up to 30 minutes to complete.

   Upon completion, you should see a new column in the dataframe called `embeddings`, which contains the embeddings values:

<!--Fran, we could use a screenshot here-->

## Configure Redis for vector search

Next, you'll configure Redis to store the embedding vectors we created in the previous step. To do this, you'll need to update the Jupyter notebook with the connection information for your Azure Cache for Redit Enterprise endpoint.

1. In the Azure portal, navigate to your cache instance's **Overview** page and copy endpoint of your Azure Cache for Redis Enterprise instance. The endpoint should resemble: `myredisinstance.eastus.redisenterprise.cache.azure.net`.

1. In the code cell with the comment `Code cell 8`, update the line of code that sets the `REDIS_HOST` variable with the endpoint of your Azure Cache for Redis Enterprise instance that you copied in the previous step.

1. In the Azure portal, navigating to the **Access keys** page and copy one of the access keys for the cache.

1. Again in the code cell with the comment `Code cell 8`, update the line of code that sets the `REDIS_PASSWORD` variable with access key you copied in the previous step.
1. Execute the cell you just edited. If the connection is sucessful, you will see `True` returned.

   > [!Important]
   > We strongly recommend using environmental variables or a secret manager like [Azure Key Vault](../key-vault/general/overview) to pass in the Redis key and hostname information. These variables are set in plaintext here for the sake of simplicity.

1. Execute the code cell with the comment `Code cell 9`. configure the Redis instance for vector search. In this example, you'll use `Cosine` as a distance metric, and a `FLAT` index method.  

1. Execute the code cell with the comment `Code cell 10`. The `index_documents()` method loads items into Redis. This can take 10+ minutes.

   Upon completion, you should see the following output.

   ```output
   Loaded 11086 documents in Redis search index with name: embeddings-index
   ```

## Execute basic vector similarity search

Now that your dataset, Azure OpenAI service API, and Redis instance are set up, you can search for vectors.

1. Execute the code cell with the comment `Code cell 11`. This code first creates an embedding vector for the user query, then prepares the query to be executed, and finally performs the vector search against the redis cache.

1. Execute the code cell with the comment `Code cell 12`. Here we call the `search_redis()` function defined in Code cell 11 and provide a natural language query.

1. Modify the code in `Code cell 12` to match the following change:

   ```python
   results = search_redis(redis_client, "Basketball comeback story with NBA players", k=10)
   ```

1. Execute code cell 12 again. If successful, you should see the following output:

   ```output
   0.Celtic Pride (Score: 0.831)
   1.Inside Moves (Score: 0.826)
   2.Space Jam (Score: 0.826)
   3.Thunderstruck (Score: 0.824)
   4.That Championship Season (Score: 0.823)
   5.BASEketball (Score: 0.822)
   6.Hurricane Season (Score: 0.819)
   7.Like Mike (Score: 0.819)
   8.Coach Carter (Score: 0.818)
   9.Blue Chips (Score: 0.816)
   ```

1. Again, modify the code in `Code cell 12` to match the following change:

   ```python
   results = search_redis(redis_client, "spaceships, explosions, area 51, aliens, and America.", k=10)
   ```

   Notice that in this example, keywords are used instead of a natural language query.

1. Execute code cell 12 again. If successful, you should see the following output:

   ```output
   0.Independence Day (Score: 0.849)
   1.Hangar 18 (Score: 0.824)
   2.UFO: Target Earth (Score: 0.823)
   3.Solar Crisis (Score: 0.821)
   4.Invaders from Mars (Score: 0.818)
   5.The Dark Side of the Moon (Score: 0.818)
   6.Mars Attacks! (Score: 0.817)
   7.The Flying Machine (Score: 0.817)
   8.Remote Control (Score: 0.817)
   9.Spaced Invaders (Score: 0.815)
   ```

<!--TODO: Provide another example-->

   Note that the similarity score is returned along with the ordinal ranking of movies by similarity. You'll notice that more specific queries will have similarity scores decrease faster down the list.

## Hybrid searches

Since RediSearch also features rich search functionality on top of vector search, it's possible to filter results by the metadata in the data set, such as film genre, cast, release year, or director.

1. Execute the code cell with the comment `Code cell 13`. Note how the `create_hybrid_field()` method filters for for the Genre _drama_.

   If successful, you should see the following output:

   ```output
   0.Inside Moves (Score: 0.826)
   1.That Championship Season (Score: 0.823)
   2.Hurricane Season (Score: 0.819)
   3.Coach Carter (Score: 0.818)
   4.Blue Chips (Score: 0.816)
   5.Sunset Park (Score: 0.814)
   6.Home Run (Score: 0.814)
   7.One on One (Score: 0.813)
   8.That Championship Season (Score: 0.813)
   9.He Got Game (Score: 0.811)
   ```

   With Azure Cache for Redis and Azure OpenAI Service, you can use embeddings and vector search to add powerful search capabilities to your application.
 
<!--TODO: Provide another example also filtering for year-->
<!--Optional TODO: clean metadata columns of spaces to make searching easier-->

## Clean up resources

If you created an OpenAI or Redis resource solely for completing this tutorial and want to clean up and remove the resources, you'll need to delete your cache instance along with your deployed AI model. You can then delete the Azure OpenAI resource or associated resource group if it's dedicated to your test resource. Deleting the resource group also deletes any other resources associated with it.

- [Portal](../../multi-service-resource.md?pivots=azportal#clean-up-resources)
- [Azure CLI](../../multi-service-resource.md?pivots=azcli#clean-up-resources)

## Next steps

- [Learn more about Azure Cache for Redis](cache-overview.md)
- Learn more about Azure Cache for Redis' [vector search capabilities](/cache-redis-modules#redisearch)
- Learn more about [embeddings generated by Azure OpenAI Service](../ai-services/openai/concepts/understand-embeddings.md)
- Learn more about [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)
- [Read how to build an AI-powered app with OpenAI and Redis](https://techcommunity.microsoft.com/t5/azure-developer-community-blog/vector-similarity-search-with-azure-cache-for-redis-enterprise/ba-p/3822059)
- [Build a Q&A app with semantic answers](https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna)
