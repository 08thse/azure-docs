---
title: "Tutorial: Use Azure Container apps sessions code interpreter in Semantic Kernel (preview)"
description: Learn to use Semantic Kernel in a code interpreter session in Azure Container Apps.
services: container-apps
author: anthonychu
ms.service: container-apps
ms.topic: tutorial
ms.date: 05/06/2024
ms.author: antchu
---

# Tutorial: Use Azure Container apps sessions code interpreter in Semantic Kernel (preview)

[Semantic Kernel](/semantic-kernel/overview/) is an open-source AI framework created by Microsoft for .NET, Python, and Java developers working with Large Language Models (LLMs). When you build an AI agent with Semantic Kernel, a large language model (LLM) interprets user input and generates a response. The AI agent often struggles when it needs to perform mathematical and symbolic reasoning to produce a response. By integrating Azure Container Apps dynamic sessions with Semantic Kernel, you give the agent a [code interpreter](sessions-code-interpreter.md) to use to perform specialized tasks.

In this tutorial, you learn how to run a Semantic Kernel AI agent in a web API app. The API accepts user input and returns a response generated by the AI agent.

> [!NOTE]
> Azure Container Apps dynamic sessions is currently in preview.

## Prerequisites

- An Azure account with an active subscription.
  - If you don't have one, you [can create one for free](https://azure.microsoft.com/free/).
- Install the [Azure CLI](/cli/azure/install-azure-cli).
- Git.
- .NET 8.0.

## Create Azure resources

The sample app in this quickstart uses an LLM from Azure OpenAI. It also uses Azure Container Apps sessions to run code generated by the LLM.

1. Update the Azure CLI to the latest version and install the Azure Container Apps extension:

   ```bash
    az upgrade
    az extension add --name containerapp --upgrade --allow-preview
    ```

1. Sign in to Azure:

   ```bash
   az login
   ```

1. Set the variables used in this quickstart:

    ```bash
    RESOURCE_GROUP_NAME=aca-sessions-demo
    OPENAI_LOCATION=swedencentral
    OPENAI_NAME=<UNIQUE_OPEN_AI_NAME>
    SESSION_POOL_LOCATION=westus2
    SESSION_POOL_NAME=code-interpreter-pool
    ```

    Replace `<UNIQUE_OPEN_AI_NAME>` with a unique name to create your Azure OpenAI account.

1. Create a resource group:

   ```bash
   az group create --name $RESOURCE_GROUP_NAME --location $SESSION_POOL_LOCATION
   ```

1. Create an Azure OpenAI account:

    ```bash
    az cognitiveservices account create \
        --name $OPENAI_NAME \
        --resource-group $RESOURCE_GROUP_NAME \
        --location $OPENAI_LOCATION \
        --kind OpenAI \
        --sku s0
    ```

1. Deploy a GPT 3.5 Turbo model in the Azure OpenAI account:

    ```bash
    az cognitiveservices account deployment create \
        --resource-group $RESOURCE_GROUP_NAME \
        --name $OPENAI_NAME \
        --deployment-name gpt-35-turbo \
        --model-name gpt-35-turbo \
        --model-version "1106" \
        --model-format OpenAI \
        --sku-capacity "100" \
        --sku-name "Standard"
    ```

1. Create a code interpreter session pool:

    ```bash
    az containerapp sessionpool create \
        --name $SESSION_POOL_NAME \
        --resource-group $RESOURCE_GROUP_NAME \
        --location $SESSION_POOL_LOCATION \
        --max-concurrent-sessions 100 \
        --pool-type PythonLTS \
        --cooldown-period 300
    ```

## Run the sample app locally

1. Clone the [Azure Container Apps sessions samples repository](#).

    ```bash
    git clone <tbd>
    ```

1. Change to the directory that contains the sample app:

    ```bash
    cd <tbd>
    ```

1. Get the Azure OpenAI account endpoint:

    ```bash
    az cognitiveservices account show \
      --name $OPENAI_NAME \
      --resource-group $RESOURCE_GROUP_NAME \
      --query properties.endpoint
    ```

1. Update the `appsettings.json` file with the Azure OpenAI account endpoint and save the file:

    ```json
    {
        "AzureOpenAIEndpoint": "<openai-endpoint>"
    }
    ```

    Replace `<openai-endpoint>` with the endpoint you retrieved in the previous step.

1. Run the sample app:

    ```bash
    dotnet run
    ```

1. Open a browser and navigate to `http://localhost:5000/chat?input=What is the current date and time?`.

    As the LLM isn't yet integrated with the code interpreter, the response isn't accurate. In the next steps, you integrate the LLM with the code interpreter to improve the response.

## Add the code interpreter plugin

The Semantic Kernel code interpreter plugin is included in `Microsoft.SemanticKernel` version `1.??.?` or later.

1. TODO: See if user needs a specific role to call Azure OpenAI with DefaultAzureCredential.

1. Get the Azure Container Apps session pool's management endpoint:

    ```bash
    az containerapp sessionpool show \
      --name $SESSION_POOL_NAME \
      --resource-group $RESOURCE_GROUP_NAME \
      --query properties.poolManagementEndpoint
    ```

1. Update the `appsettings.json` file with the Azure Container Apps session pool management endpoint and save the file:

    Before you run this command, replace `<SESSION_POOL_MANAGEMENT_ENDPOINT>` with the endpoint you retrieved in the previous step. It should be in the format `https://<LOCATION>.dynamicsessions.io/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP_NAME>/sessionPools/<SESSION_POOL_NAME>/`.

    ```json
    {
        "PoolManagementEndpoint": "<SESSION_POOL_MANAGEMENT_ENDPOINT>"
    }
    ```


1. At the top of the `ChatController.cs` file, add the following using statement:

    ```csharp
    using Microsoft.SemanticKernel.CodeInterpreter;
    ```

1. In the `ChatController.cs` file, below the line `// TODO: Add code interpreter plugin`, add the following code:

    ```csharp
    builder.Plugins.AddFromObject(await SessionsPythonReplPlugin.CreateAsync(sessionPoolManagementEndpoint));
    ```

1. Save the file and run the sample app:

    ```bash
    dotnet run
    ```

1. Open a browser and navigate to `http://localhost:5000/chat?input=What is the current date and time?`.

    The response is now accurate because the LLM is integrated with the code interpreter. See the console output for the code interpreter session logs. Notice that each time you send a request, a new session is created and used to run the code. Code generated by an LLM is untrusted because it can contain malicious instructions. The code interpreter plugin ensures that the code is run in a secure environment.

By default, the code interpreter plugin uses [`DefaultAzureCredential`](/dotnet/api/azure.identity.defaultazurecredential?view=azure-dotnet&preserve-view=true) to authenticate with Azure Container Apps to execute code in a session. When you run the app locally, it uses your Azure CLI credentials to authenticate. In a production environment, you should use a managed identity to authenticate with Azure Container Apps. The identity requires the `Azure ContainerApps Session Creator` or `Contributor` role assignment on the session pool.

## Optional: Deploy the sample app to Azure Container Apps

To deploy the web API app to Azure Container Apps, you need to create a container image and push it to a container registry. Then you can deploy the image to Azure Container Apps. The `az containerapp up` command combines these steps into a single command.

You then need to configure managed identity for the app and assign the identity the `Azure ContainerApps Session Creator` or `Contributor` role on the session pool.

1. Build and deploy the app to Azure Container Apps:

    ```bash
    az containerapp up \
      --name "semantic-kernel-app" \
      --resource-group $RESOURCE_GROUP_NAME \
      --location $SESSION_POOL_LOCATION \
        --environment "my-container-app-env" \
        --env-vars "AzureOpenAIEndpoint=<OPEN_AI_ENDPOINT>" "PoolManagementEndpoint=<SESSION_POOL_MANAGMENT_ENDPOINT>" \
        --source .
    ```

1. Enable the system-assigned managed identity for the app:

    ```bash
    az containerapp identity assign \
      --name "semantic-kernel-app" \
      --resource-group $RESOURCE_GROUP_NAME \
      --system-assigned
    ```

1. Get the managed identity's principal ID, the container app's resource ID, and fully qualified domain name (FQDN):

    ```bash
    az containerapp show \
      --name "semantic-kernel-app" \
      --resource-group $RESOURCE_GROUP_NAME \
      --query "{principalId:identity.principalId, resourceId:id, fqdn:properties.configuration.ingress.fqdn}"
    ```

1. Assign the managed identity the `Azure ContainerApps Session Creator` role on the session pool:

    Before you run the following command, replace `<PRINCIPAL_ID>` and `<RESOURCE_ID>` with the values you retrieved in the previous step.

    ```bash
    az role assignment create \
      --role "Azure ContainerApps Session Creator" \
      --assignee <PRINCIPAL_ID> \
        --scope <RESOURCE_ID>
    ```


1. TODO: Give the managed identity the proper role to call Azure OpenAI.

1. Open the browser to `https://<fqdn>/chat?input=What is the current date and time?` to test the deployed app.

## Clean up resources

When you're done with the resources, you can delete them to avoid incurring charges:

```bash
az group delete --name $RESOURCE_GROUP_NAME --yes --no-wait
```

## Next steps

> [!div class="nextstepaction"]
> [Code interpreter sessions](./sessions-code-interpreter.md)
