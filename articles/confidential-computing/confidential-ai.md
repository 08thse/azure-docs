---

title: Confidential AI

description: Confidential AI services and solutions

services: virtual-machines

author: kapilv

ms.service: virtual-machines

ms.subservice: confidential-computing

ms.workload: infrastructure

ms.topic: conceptual

ms.date: 05/17/2023

ms.author: kapilv

---

# Confidential AI

## What is Confidential AI?
AI has been shaping several industries such as finance, advertising, manufacturing, and healthcare well before the recent progress in generative AI. Generative AI models have the potential to create an even larger impact on society. Microsoft has been at the forefront of defining the [principles of Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai) to serve as a guardrail for responsible use of AI technologies. Confidential computing and confidential AI are a key tool to enable security and privacy in the Responsible AI toolbox.

Confidential AI is a set of hardware-based technologies that provide strong, cryptographically verifiable protection of data and models throughout the AI lifecycle, including when data and models are in use. This include accelerators such as GPUs that support confidential computing, and confidential services that enable data collection, pre-processing and . Confidential AI also provides tools to increase trust, transparency, and accountability in AI deployments.

## What scenarios does Confidential AI address? 

Confidential AI addresses several scenarios spanning the entire AI
lifecycle.

-   **Confidential Training**. Confidential AI protects training data, model architecture, and model weights during training. Just protecting weights from advanced attackers such as rogue administrators, insiders, and cloud service providers can be quite critical in scenarios where model training is resource intensive and/or involves sensitive model IP, even if the training data and the model architecture are public. With confidential training, models builders can ensure that model weights and intermediate data such as checkpoints and gradient updates exchanged between nodes during training are not visible outside TEEs. 

-   **Confidential Fine-tuning**. It is quite common to fine-tune generic AI models using domain specific, private data to improve precision for specific tasks. For example, a financial organization may fine-tune an existing language model using proprietary financial data. Confidential AI can be used to protect proprietary data and the trained model during fine-tuning.

-   **Confidential Multi-party Training**. Confidential AI enables a new class of [multi-party training scenarios](https://learn.microsoft.com/en-us/azure/confidential-computing/multi-party-data) where multiple organizations can collaborate to train models without ever exposing their models or data to each other, and enforcing policies on how the outcomes of the collaboration are shared between the participants.

-   **Confidential Federated Learning**. Federated learning has been proposed as an alternative to centralized/distributed training for scenarios where training data cannot be aggregated e.g., due to data residency requirements or security concerns. When combined with federated learning, confidential computing can provide stronger security and privacy. For example, gradient updates generated by each client can be protected from the model builder by hosting the central aggregator in a TEE. Similarly, model developers can build trust in the trained model by requiring that clients run their training pipelines in TEEs. This ensures that each client’s contribution to the model has been generated using a valid, pre-certified process without requiring access to the client’s data.

-   **Confidential Inferencing**. A typical model deployment involves several participants, including model developers who are concerned about their model IP, clients who send inferencing requests (e.g., prompts) containing sensitive data, service operators, cloud service providers. Confidential inferencing enables verifiable protection of model IP, and at the same time, protection of inferencing requests and responses from the model developer, service operations and the cloud provider. For example, confidential AI can be used to guarantee to clients that their requests are used only for a specific inference task, and that the response is only sent to them over a secure connection that terminates within a TEE.


## What are the industry use cases for Confidential AI?

With Azure Confidential Computing, customers and partners are building Confidential AI solutions addressing a number of use cases.

1.  **Autonomous driving**. Models for autonomous driving require labelled video streams that contain private data such as images, names, and addresses. In these scenarios, consent as a means for meeting privacy requirements is not practical. Confidential AI allows data processors to scrub the video streams and then train models while protecting the data throughout its lifecycle.

2.  **Anti-money laundering/Fraud detection**. Confidential AI allows multiple banks to share data with each other for the purpose of training more accurate AML models without exposing personal data of their customers. Models trained using combined datasets can detect the movement of money by one user between multiple banks, without the banks accessing each other's data. Through confidential AI, these financial institutions can increase fraud detection rates, and reduce false positives.

3.  **Assisted diagnostics and predictive healthcare**. Development of diagnostics and predictive healthcare models requires access to highly sensitive healthcare data. Getting access to such datasets is both expensive and time consuming. Confidential AI can unlock the value in such datasets, enabling AI models to be trained using sensitive data while protecting both the datasets and models throughout the lifecycle.

## Why confidential computing?

The effectiveness of AI models depends both on the quality and quantity of training data. While much progress has been made by training models using publicly available datasets, enabling models to perform accurately complex advisory tasks such as medical diagnosis, financial risk assessment, or business analysis will require access to private data.

The data that could be used to train the next generation of models already exists, but it is both private (by policy or by law) and scattered across many independent entities: medical practices and hospitals, banks and financial service providers, logistic companies, and consulting firms. A handful of these players may have enough data to create their own models, but start-ups at the cutting edge of AI innovation do not have access to these datasets.

Confidential computing can unlock access to sensitive datasets while meeting privacy and compliance concerns of data providers and the public at large. With confidential computing, data providers can authorize the use of their datasets for specific tasks (verified by attestation), such as training or fine-tuning an agreed upon model, while keeping the data protected. Model builders can use become more transparent about the choices they make during training by using confidential computing to generate non-repudiable provenance records of their entire training process. 

Using remote attestation, end users can protect their privacy by checking that inference services do not collect their inference requests and responses for unauthorized purposes. 

## What are the options to get started? 

### ACC platform offerings that help enable Confidential AI

The ACC platform offers several building blocks to roll out your own Confidential AI solution.

-   [Confidential
    VMs on SNP](https://learn.microsoft.com/en-us/azure/confidential-computing/confidential-vm-overview) and [TDX](https://techcommunity.microsoft.com/t5/azure-confidential-computing/preview-introducing-dcesv5-and-ecesv5-series-confidential-vms/ba-p/3800718) (in limited preview). CPU based AI workloads e.g., data pre-processing, and training and inferencing for smaller models can use Confidential VMs based on SNP and TDX to protect sensitive code and data from the cloud provider.

-   [Confidential Containers on ACI](https://learn.microsoft.com/en-us/azure/container-instances/container-instances-confidential-overview).
    Confidential Containers on ACI are another way of deploying containerized workloads on Azure. In addition to protection from the cloud provider, confidential containers offer protection from tenant admins and strong integrity properties using container policies. This makes them a great match for low-trust, multi-party collaboration scenarios. See [here](https://github.com/microsoft/confidential-ai) for a sample demonstrating confidential inferencing based on unmodified NVIDIA Triton inferencing server.

For AI workloads that rely on GPUs, Microsoft and NVIDIA are collaborating to bring confidential computing to NVIDIA GPUs. [Azure Confidential GPU VMs](https://azure.microsoft.com/en-us/blog/azure-confidential-computing-with-nvidia-gpus-for-trustworthy-ai/) based on AMD SEV-SNP and A100 GPUs are currently in [limited private preview](https://aka.ms/accgpusignup).

### ACC partner solutions that enable Confidential AI

Use a partner that has built Confidential AI solutions on top of the Azure confidential computing platform.

-   [Beekeeper AI](https://www.beekeeperai.com/) enables healthcare AI through a secure collaboration platform for algorithm owners and data stewards. BeeKeeperAI uses privacy-preserving analytics on multi-institutional sources of protected data in a confidential computing environment. The solution supports end-to-end encryption, secure computing enclaves, and Intel's latest SGX enabled processors to protect the data and the algorithm IP.

-   [Mythril Security](https://www.mithrilsecurity.io/) provides tooling to help SaaS vendors serve AI models inside secure enclaves, and providing an on-premises level of security and control to data owners. Data owners can use their SaaS AI solutions while remaining compliant and in control of their data.

-   [Anjuna](https://www.anjuna.io/use-case-solutions) provides a confidential computing platform to enable various use cases for organizations to develop machine learning models without exposing sensitive information.

-   [Opaque](https://opaque.co/) provides a confidential computing platform for collaborative analytics and AI, giving the ability to perform analytics while protecting data end-to-end and enabling organizations to comply with legal and regulatory mandates.

-   [Fortanix](https://www.fortanix.com/platform/confidential-ai) provides a confidential computing platform that can enable confidential AI, including multiple organizations collaborating together for multi-party analytics.


